---
layout: post
title:  "[AI] 9. Metrics, RNN"
subtitle: " Learn about Metric and Recurrent Neural Network"
category: [AI]
cover-img: /img/aipic.jpg
thumbnail-img: ""
tags: [AI]
comments: false
use_math: true
---

## 미래연구소 16기 강의 기반 정리

[http://futurelab.creatorlink.net/](http://futurelab.creatorlink.net/)

<br />

## 딥러닝 강의 9주차 -  Metrics, RNN

<br />

# 1) Metrics

모델을 평가하기 위해서 사용되는 지표이다.

## Metrics 종류

![ml3](https://user-images.githubusercontent.com/86182583/132462855-2b278409-51a3-4e75-987d-d42041d6b874.PNG)

<br />

### 1. Regression

1) MAE (Mean Absolute Error)

$$ MAE = \frac{\sum{|y-ŷ|}}{n} $$

- 특이값(Outlier)에 영향을 덜 받는다

- 절대값을 취하므로 차이를 더 객관적으로 느낄 수 있다

|ŷ|y|
|---|---|
|1|4|
|2|4|
|3|4|
|100|4|

$$ MAE = \frac{\sum{3+2+1+96}}{4}  = 25.5 $$

<br />

2) RMSE (Root Mean Square Error)

$$ RMSE = \sqrt{\frac{\sum{(y-ŷ)^{2}}}{n}} $$

- 특이값에 더 가중치를 두는 방식이다

- MAE보다 더 보편적으로 사용된다.

|ŷ|y|
|---|---|
|1|4|
|2|4|
|3|4|
|100|4|

$$ RMSE = \sqrt{\frac{9+4+1+96^{2}}}{4}} = 48.03 $$

100 이라는 Outlier에 상대적으로 더 민감하게 반응하는 것을 볼 수 있다.

<br />

### 2. Classification

![ml3](https://user-images.githubusercontent.com/86182583/132465331-7ee88eae-0c89-432a-9775-8cfa0171cdfe.PNG)

만일 암을 판정하는 AI가 위와 같은 정확도를 보였을 때, 이것을 실전에 사용할 수 있겠는가?

**Accuracy** : 전체에서 옳은 것을 맞게 보고 (암 환자에게 암 판정), 틀린 것을 틀리게 본 비율(정상 환자에게 정상 판정)

Acc = $$ \frac{(2 + 988)}{(2+3+7+988)} = 99 %

매우 높은 정확도를 보이는 것 같다. 다만 이 방법으로 정확한 성능을 측정할 수 있을까?

여기서 키트에서 암환자를 정상으로 판정하는 사람이 7명인데, 이 케이스가 많을 수록 이 제품은 치명적이다.

이는 **Data가 Imbalance**하게 있는 것을 보여주며, performance가 다른 기준으로 측정되어야한다.

왜 옳지 않은지는 **Precision**과 **Recall**을 보면 알 수 있다.

<br />

그 전에 참과 거짓을 판별하는 Confusion Matrix를 보자.

![confusion](https://user-images.githubusercontent.com/86182583/132472019-416359a9-a87c-4e7a-b1ee-a93485b2f510.png)

환자의 암을 예측하는 모델이라고 했을 때

실제 환자가 암이고, 예측 결과도 암이면 True Positive(TP),

실제 환자는 암이지만, 예측 결과는 정상이면 False Negative(FN),

실제 환자는 정상이지만, 예측 결과가 암이라면 False Positive(FP),

실제 환자는 정상이고, 예측결과도 정상이면 True Negative(TN) 이다.

<br />

### 1. Precision

정밀도라고도 하며, **Positive(양성) 판정**이 맞을 확률을 나타낸다.

암이라고 판정 했을 때 실제로 맞을 확률

$$ (Precision) = \frac{TP}{TP + FP}$$

$$ (예시 Precision) = \frac{2}{2 + 3} = 40% $$

![precisionex](https://user-images.githubusercontent.com/86182583/132473093-ac191564-204e-4cdf-8f23-26fb9f934cc7.PNG)

<br />

### 2. Recall

재현율이라고도 하며 라고도 하며, **Positive(양성) 판정**이 맞았는지를 나타낸다.

암 환자 중에 실제로 암을 진단 받을 확률

$$ (Recall) = \frac{TP}{TP + FN}$$

$$ (예시 Recall) = \frac{2}{2 + 7} ≈ 22% $$

![recallex](https://user-images.githubusercontent.com/86182583/132474159-3d0a3bd0-b40f-45b0-93fb-d60ef4594e73.PNG)

<br />

### 3. Data Imbalance

각 클래스가 갖고 있는 데이터의 차이가 큰 경우를 지칭한다.

암 환자와 암 환자가 아닌 경우가 어느 정도 비슷해야 사용하는데

일반적으로 암 환자가 실험에 참여할 경우가 현격하게 적다. (2+7 = 9 vs 3+988 = 991)

이렇게 Data가 Imbalance하거나 잘못된 Metric을 활용할 경우 오류를 파악할 수 없다.

### 4. F1 Score

데이터가 class 별로 고르면(Balanced) Accuracy를 사용하면 되지만

만일 그렇지 않다면 recall과 precision의 조화 평균인 F1 Score라는 지표를 이용한다.

$$ (F1 Score) = \frac{2}{\frac{1}{recall}+\frac{1}{precision}} = \frac{2*(precision)*(recall)}{(precision)*(recall)} $$

<br />
<br />

# 2) RNN (Recurrent Neural Network)

순환 신경망이다. 순서가 의미 있는 데이터를 처리할 때 자주 쓰는 모델이다

시간 별로 변동하는 시계열 데이터나, 앞 뒤 문장이 존재하는 자연어 처리 등에 사용되는 알고리즘이다.

실제로는 현재 자주 쓰이진 않지만, 다른 알고리즘들의 이론적 토대가 되기 때문에 알아둘 필요가 있다.



<br />
<br />
