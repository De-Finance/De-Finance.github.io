---
layout: post
title:  "[AI] 9. Metrics, RNN"
subtitle: " Learn about Metric and Recurrent Neural Network"
category: [AI]
cover-img: /img/aipic.jpg
thumbnail-img: ""
tags: [AI]
comments: false
use_math: true
---

## 미래연구소 16기 강의 기반 정리

[http://futurelab.creatorlink.net/](http://futurelab.creatorlink.net/)

<br />

## 딥러닝 강의 9주차 -  Metrics, RNN

<br />

# 1) Metrics

모델을 평가하기 위해서 사용되는 지표이다.

## Metrics 종류

![ml3](https://user-images.githubusercontent.com/86182583/132462855-2b278409-51a3-4e75-987d-d42041d6b874.PNG)

<br />

### 1. Regression

1) MAE (Mean Absolute Error)

$$ MAE = \frac{\sum{|y-ŷ|}}{n} $$

- 특이값(Outlier)에 영향을 덜 받는다

- 절대값을 취하므로 차이를 더 객관적으로 느낄 수 있다

|ŷ|y|
|---|---|
|1|4|
|2|4|
|3|4|
|100|4|

$$ MAE = \frac{\sum{3+2+1+96}}{4}  = 25.5 $$

<br />

2) RMSE (Root Mean Square Error)

$$ RMSE = \sqrt{\frac{\sum{(y-ŷ)^{2}}}{n}} $$

- 특이값에 더 가중치를 두는 방식이다

- MAE보다 더 보편적으로 사용된다.

|ŷ|y|
|---|---|
|1|4|
|2|4|
|3|4|
|100|4|

$$ RMSE = \sqrt{\frac{9+4+1+96^{2}}}{4}} = 48.03 $$

100 이라는 Outlier에 상대적으로 더 민감하게 반응하는 것을 볼 수 있다.

<br />

### 2. Classification

![ml3](https://user-images.githubusercontent.com/86182583/132465331-7ee88eae-0c89-432a-9775-8cfa0171cdfe.PNG)

만일 암을 판정하는 AI가 위와 같은 정확도를 보였을 때, 이것을 실전에 사용할 수 있겠는가?

**Accuracy** : 전체에서 옳은 것을 맞게 보고 (암 환자에게 암 판정), 틀린 것을 틀리게 본 비율(정상 환자에게 정상 판정)

Acc = $$ \frac{(2 + 988)}{(2+3+7+988)} = 99 %

매우 높은 정확도를 보이는 것 같다. 다만 이 방법으로 정확한 성능을 측정할 수 있을까?

여기서 키트에서 암환자를 정상으로 판정하는 사람이 7명인데, 이 케이스가 많을 수록 이 제품은 치명적이다.

이는 **Data가 Imbalance**하게 있는 것을 보여주며, performance가 다른 기준으로 측정되어야한다.

왜 옳지 않은지는 **Precision**과 **Recall**을 보면 알 수 있다.

<br />

그 전에 참과 거짓을 판별하는 Confusion Matrix를 보자.

![confusion](https://user-images.githubusercontent.com/86182583/132472019-416359a9-a87c-4e7a-b1ee-a93485b2f510.png)

환자의 암을 예측하는 모델이라고 했을 때

실제 환자가 암이고, 예측 결과도 암이면 True Positive(TP),

실제 환자는 암이지만, 예측 결과는 정상이면 False Negative(FN),

실제 환자는 정상이지만, 예측 결과가 암이라면 False Positive(FP),

실제 환자는 정상이고, 예측결과도 정상이면 True Negative(TN) 이다.

<br />

### 1. Precision

정밀도라고도 하며, **Positive(양성) 판정**이 맞을 확률을 나타낸다.

암이라고 판정 했을 때 실제로 맞을 확률

$$ (Precision) = \frac{TP}{TP + FP}$$

$$ (예시 Precision) = \frac{2}{2 + 3} = 40% $$

![precisionex](https://user-images.githubusercontent.com/86182583/132473093-ac191564-204e-4cdf-8f23-26fb9f934cc7.PNG)

<br />

### 2. Recall

재현율이라고도 하며 라고도 하며, **Positive(양성) 판정**이 맞았는지를 나타낸다.

암 환자 중에 실제로 암을 진단 받을 확률

$$ (Recall) = \frac{TP}{TP + FN}$$

$$ (예시 Recall) = \frac{2}{2 + 7} ≈ 22% $$

![recallex](https://user-images.githubusercontent.com/86182583/132474159-3d0a3bd0-b40f-45b0-93fb-d60ef4594e73.PNG)

<br />

### 3. Data Imbalance

각 클래스가 갖고 있는 데이터의 차이가 큰 경우를 지칭한다.

암 환자와 암 환자가 아닌 경우가 어느 정도 비슷해야 사용하는데

일반적으로 암 환자가 실험에 참여할 경우가 현격하게 적다. (2+7 = 9 vs 3+988 = 991)

이렇게 Data가 Imbalance하거나 잘못된 Metric을 활용할 경우 오류를 파악할 수 없다.

### 4. F1 Score

데이터가 class 별로 고르면(Balanced) Accuracy를 사용하면 되지만

만일 그렇지 않다면 recall과 precision의 조화 평균인 F1 Score라는 지표를 이용한다.

$$ (F1 Score) = \frac{2}{\frac{1}{recall}+\frac{1}{precision}} = \frac{2*(precision)*(recall)}{(precision)*(recall)} $$

<br />
<br />

# 2) RNN (Recurrent Neural Network)

순환 신경망이다. 순서가 의미 있는 데이터를 처리할 때 자주 쓰는 모델이다

실제로는 현재 자주 쓰이진 않지만, 다른 알고리즘들의 이론적 토대가 되기 때문에 알아둘 필요가 있다.

우리가 아는 Neural Network들이 여러개 존재하는데, 하나의 단위를 Cell이라고 부르며, 여기서 Cell들은 한 방향으로 연결되어 있어서 이전 값이 현재 학습에 영향을 주도록 설계 되어 있다.

따라서 주가 같이 시간 별로 변동하는 시계열 데이터나, 앞 뒤 문장을 통해 문맥에 따라 학습하는 자연어 처리 등에 사용된다.

![RNN_1](https://user-images.githubusercontent.com/86182583/132681262-78a88f95-c18f-4639-8260-4e9696707b77.png)

<br />

### RNN의 종류

![rnnimg](https://user-images.githubusercontent.com/86182583/132681926-3f40a54f-85c9-4de9-9579-412b404ad9a5.png)

1. one to one : 기존에 배운 Dense Layer다.

2. one to many : image captioning 같이 한 이미지에 여러 분류 필요할 때 쓰임

3. many to one : 글을 읽고 긍정/부정 분석하는 sentiment classification에 사용된다.

4. many to many : 문장 끝까지 읽은 시점부터 변역된 문장을 출력한다. (Machine Translation)

5. many to many (without timelag) : Video classification 과거부터 현재까지의 image를 통해 output을 출력한다.

<br />

### RNN의 구조

![rnninput](https://user-images.githubusercontent.com/86182583/132682988-c11e92f5-b60d-48e3-b650-c0a3bbd3e5bd.PNG)

1> sample: sample 개수 (1 회 train 기준 = batch_size)

2> time_step = input_length: 어느 정도의 시간을 고려하여 학습할 것인가

3> input_dim: input data 의 feature 수

<br />

![rnn2](https://user-images.githubusercontent.com/86182583/132683340-1ec970c1-748c-4e75-86ee-3716090abb59.PNG)

다음과 같은 주가 데이터가 있을 때, 빨간 박스에 있는 것이 하나의 data이면

time_step은 3일치 데이터이며, input dimension은 시가, 고가 저가, 종가로 4다.

각각의 데이터들은 RNN의 각 input에 들어가게 되며 학습을 한다.

![rnn3](https://user-images.githubusercontent.com/86182583/132684005-28d4cc15-dfa8-4bc6-b4e8-f34ffc232540.PNG)

<br />

각 input 마다 있는 hidden unit들을 하나의 cell이라고 한다

cell 연산 같은 경우에는 현재 cell에서의 계산 값에 이전 계산 값이 들어와 합하고

tanh activation function을 통해 결과가 도출된다.

![rnn4img](https://user-images.githubusercontent.com/86182583/132685482-5ed3c6d8-ea05-495f-8c3d-c77ded552f37.png)

<br />

1. $$ W_{xh}x_{t} $$ 가  현재 input layer를 연산하는 것이고

2. $$ W_{hh}h_{t-1} + W_{xh}x_{t} $$ 가 이전 unit의 연산값을 받는다.

3. 여기에 activation을 씌워 현재 계산 값을 완성 시키는데 

$$ h_{t} = tanh(W_{hh}h_{t-1} + W_{xh}x_{t}) $$ 이고

$$ y_{t} = W_{hy}h_{t} $$ 가 최종 결과로 나온다. 

<br />

1> 동일 layer 에서는 $$ W_{xh} = W_{hh} = W_{hy} $$

2> return_sequence 를 통해 output 의 dimension 을 input 과 같게 할 수 있고 이를 통해 Recurrent Layer 를 더 붙일 수 있다

3> 보통 연산할 때 bias도 붙인다.



<br />
<br />
