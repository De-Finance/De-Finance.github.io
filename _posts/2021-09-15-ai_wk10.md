---
layout: post
title:  "[AI] 10. Saving Model, Callback"
subtitle: " Learn about finishing touches with the model"
category: [AI]
cover-img: /img/aipic.jpg
thumbnail-img: ""
tags: [AI]
comments: false
use_math: true
---

## 미래연구소 16기 강의 기반 정리

[http://futurelab.creatorlink.net/](http://futurelab.creatorlink.net/)

<br />

## 딥러닝 강의 10주차 - Saving Model, Callback

<br />

이번 글은 이론보단 실전 코드와 함께 정리를 해 놓았습니다.

<br />

# 1. The Method for saving model

모델을 저장하는 코드에서 .h5라는 파일이 저장되는데

이는 **HDF5**를 줄인 것이며, Hierarchical Data Format의 약자이다

기존에 과학자들이 데이터 관리할 때 주로 사용하였다.

공용 파일이기 때문에 모델을 저장하고 배포하기 용이하다.

<br />

## Model의 저장

h5 파일은 keras 모델의 다양한 요소를 저장하는데, 다음과 같은 요소를 포함한다.

- 모델의 레이어 및 연결방법을 지정하는 아키텍처 및 구성
- 가중치 값의 집합 (모델 상태)
- Optimizer
- 모델을 컴파일링하거나 `add_loss()` 또는 `add_metric()`을 호출하여 정의된 손실 및 메트릭의 집합

이런 요소들은 전체 혹은 일부로 저장할 수 있다.

하나는 train한 모델 전체를 저장하는 것이고

아니면 model의 architecture를 저장하고,

학습된 weight 값들만 저장하는 방법도 있다.

<br />

### 1. **모델 전체 저장**

저장을 할 때는 `model.save('파일이름.h5')` 로 **저장**한다. (저장 위치가 다르면 경로도 앞에 붙어준다.)

저장한 것을 불러올 때는 `new_model = load_model('파일이름.h5')` 이다.

모델 전체를 저장하면 바로 predict를 통해 학습된 모델을 사용할 수 있다.

np.argmax( `new_model.predict(x_test[0:9])`, axis=1)

<br />

### 2. **모델 architecture 저장**

JSON 파일 형태로 모델의 구성을 저장한다.

`json_string = model.to_json()` 로 모델의 구조를 저장한다.

`json_string`에는 다음과 같이 json 형태로 모델의 구조가 저장되어 있다.

```py
{"class_name": "Sequential", "config": {"name": "sequential", "layers": [{"class_name": "InputLayer", "config": {"batch_input_shape": [null, 784], "dtype": "float32", "sparse": false, "ragged": false, "name": "dense_input"}}, {"class_name": "Dense", "config": {"name": "dense", "trainable": true, "batch_input_shape": [null, 784], "dtype": "float32", "units": 32, "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "GlorotUniform", "config": {"seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": null, "kernel_constraint": null, "bias_constraint": null}}, {"class_name": "Dense", "config": {"name": "dense_1", "trainable": true, "dtype": "float32", "units": 64, "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "GlorotUniform", "config": {"seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": null, "kernel_constraint": null, "bias_constraint": null}}, {"class_name": "Dense", "config": {"name": "dense_2", "trainable": true, "dtype": "float32", "units": 128, "activation": "relu", "use_bias": true, "kernel_initializer": {"class_name": "GlorotUniform", "config": {"seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": null, "kernel_constraint": null, "bias_constraint": null}}, {"class_name": "Dense", "config": {"name": "dense_3", "trainable": true, "dtype": "float32", "units": 10, "activation": "softmax", "use_bias": true, "kernel_initializer": {"class_name": "GlorotUniform", "config": {"seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": null, "kernel_constraint": null, "bias_constraint": null}}]}, "keras_version": "2.4.0", "backend": "tensorflow"}
```

모델을 불러오는 것은 `model_from_json()` 함수를 사용한다.

```py
from tensorflow.keras.models import model_from_json
model_json = model_from_json(json_string)

model_json.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                 metrics=['accuracy'])

loss, acc = model_json.evaluate(x_test,  y_test, verbose=2)
```
이렇게 구조를 바로 불러오면 우리가 모델을 적지 않고 바로 컴파일 단계로 넘어갈 수 있다.

<br />

### 3. **모델 weight만 저장**

모델의 가중치 값만 저장되어 있는 형태다.

최근에 전이 학습에서 학습 시간을 획기적으로 줄이고자 다음과 같이 시작 가중치 값만 불러 새 모델을 train한다.

**저장** : `new_model.save_weights('파일이름.h5')`

**로딩** : `new_model.load_weights('파일이름.h5')`

<br />
<br />

# 2. Callback

학습을 하는 중간에 (epoch를 돌면서) 결과를 확인한다.

- ModelCheckpoint
- EarlyStopping
- LearningRateScheduler
- Tensorboard

등 모델을 만들 때 유용한 기능들에 대해 알아보자.

<br />

## 1) ModelCheckpoint

한 epoch의 끝인 특정 지점(checkpoint)을 저장하여 나중에 불러낼 수 있게 만든다.

[ModelCheckpoint 공식문서](https://keras.io/api/callbacks/model_checkpoint/)

```py
from tensorflow.keras.callbacks import ModelCheckpoint
import os

checkpoint_path = "training_1/cp.ckpt" # ckpt: checkpoint의 약자
checkpoint_dir = os.path.dirname(checkpoint_path)

# 체크포인트 콜백 만들기
cp_callback = ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=1)
```


<br />

### 2. Classification

![ml3](https://user-images.githubusercontent.com/86182583/132465331-7ee88eae-0c89-432a-9775-8cfa0171cdfe.PNG)

만일 암을 판정하는 AI가 위와 같은 정확도를 보였을 때, 이것을 실전에 사용할 수 있겠는가?

**Accuracy** : 전체에서 옳은 것을 맞게 보고 (암 환자에게 암 판정), 틀린 것을 틀리게 본 비율(정상 환자에게 정상 판정)

Acc = $$ \frac{(2 + 988)}{(2+3+7+988)} = 99 %

매우 높은 정확도를 보이는 것 같다. 다만 이 방법으로 정확한 성능을 측정할 수 있을까?

여기서 키트에서 암환자를 정상으로 판정하는 사람이 7명인데, 이 케이스가 많을 수록 이 제품은 치명적이다.

이는 **Data가 Imbalance**하게 있는 것을 보여주며, performance가 다른 기준으로 측정되어야한다.

왜 옳지 않은지는 **Precision**과 **Recall**을 보면 알 수 있다.

<br />

그 전에 참과 거짓을 판별하는 Confusion Matrix를 보자.

![confusion](https://user-images.githubusercontent.com/86182583/132472019-416359a9-a87c-4e7a-b1ee-a93485b2f510.png)

환자의 암을 예측하는 모델이라고 했을 때

실제 환자가 암이고, 예측 결과도 암이면 True Positive(TP),

실제 환자는 암이지만, 예측 결과는 정상이면 False Negative(FN),

실제 환자는 정상이지만, 예측 결과가 암이라면 False Positive(FP),

실제 환자는 정상이고, 예측결과도 정상이면 True Negative(TN) 이다.

<br />

### 1. Precision

정밀도라고도 하며, **Positive(양성) 판정**이 맞을 확률을 나타낸다.

암이라고 판정 했을 때 실제로 맞을 확률

$$ (Precision) = \frac{TP}{TP + FP}$$

$$ (예시 Precision) = \frac{2}{2 + 3} = 40% $$

![precisionex](https://user-images.githubusercontent.com/86182583/132473093-ac191564-204e-4cdf-8f23-26fb9f934cc7.PNG)

<br />

### 2. Recall

재현율이라고도 하며 라고도 하며, **Positive(양성) 판정**이 맞았는지를 나타낸다.

암 환자 중에 실제로 암을 진단 받을 확률

$$ (Recall) = \frac{TP}{TP + FN}$$

$$ (예시 Recall) = \frac{2}{2 + 7} ≈ 22% $$

![recallex](https://user-images.githubusercontent.com/86182583/132474159-3d0a3bd0-b40f-45b0-93fb-d60ef4594e73.PNG)

<br />

### 3. Data Imbalance

각 클래스가 갖고 있는 데이터의 차이가 큰 경우를 지칭한다.

암 환자와 암 환자가 아닌 경우가 어느 정도 비슷해야 사용하는데

일반적으로 암 환자가 실험에 참여할 경우가 현격하게 적다. (2+7 = 9 vs 3+988 = 991)

이렇게 Data가 Imbalance하거나 잘못된 Metric을 활용할 경우 오류를 파악할 수 없다.

### 4. F1 Score

데이터가 class 별로 고르면(Balanced) Accuracy를 사용하면 되지만

만일 그렇지 않다면 recall과 precision의 조화 평균인 F1 Score라는 지표를 이용한다.

$$ (F1 Score) = \frac{2}{\frac{1}{recall}+\frac{1}{precision}} = \frac{2*(precision)*(recall)}{(precision)*(recall)} $$

<br />
<br />

# 2) RNN (Recurrent Neural Network)

순환 신경망이다. 순서가 의미 있는 데이터를 처리할 때 자주 쓰는 모델이다

시간 별로 변동하는 시계열 데이터나, 앞 뒤 문장이 존재하는 자연어 처리 등에 사용되는 알고리즘이다.

실제로는 현재 자주 쓰이진 않지만, 다른 알고리즘들의 이론적 토대가 되기 때문에 알아둘 필요가 있다.



<br />
<br />
