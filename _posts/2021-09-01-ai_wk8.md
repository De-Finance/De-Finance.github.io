---
layout: post
title:  "[AI] 8. Convolutional Neural Network"
subtitle: " Learn about Image Processing"
category: [AI]
cover-img: /img/aipic.jpg
thumbnail-img: ""
tags: [AI]
comments: false
use_math: true
---

## 미래연구소 16기 강의 기반 정리

[http://futurelab.creatorlink.net/](http://futurelab.creatorlink.net/)

<br />

## 딥러닝 강의 8주차 -  Convolutional Neural Network

<br />

CNN 이라고도 불리며, 이미지 분류/인식에서 많이 사용된다.

GPU 연산에 최적화되어 연산이 빠릅니다.

따라서 자연어 처리 (Natural Language Processing) 에서도 긴 Sequence를 처리할 때 사용하기도 한다.

<br />

기존 방식: 특징을 일일이 정의하여 물체를 분류 하였다. (ex. 뾰족한 귀 모양 * 2, 얼굴 곡선 부분 * 1, 꼬리 * 1 ... == 고양이로 정의)

우리 뇌도 이런 작은 특징(Feature)들을 조합하여 물체를 인식한다.

머신러닝에선 이런 특징을 신경망 형태로 계층적으로 학습한다.

다만 이런 특징만이 아니라 **공간 정보**도 물체를 판단할 때 중요하게 작용한다.

특징이 다 있어도 완전히 섞여 있으면 물체를 인식하지 못하기 때문이다.

<br />

![fully_connected_0](https://user-images.githubusercontent.com/86182583/131289061-f96ad686-d82e-48e2-a430-2e7a4039011e.PNG)

지금까지 우리가 배운 NN은 모든 노드들이 연결되어 있는 Fully Connected Layer로 이루어져 있었다.

다만 이 경우에는 공간을 인식하는데는 문제가 생길 수 있다.

이미지 같은 경우는 2D나 3D 이미지를 1차원 숫자로 Flatten하여 Input으로 넣는다.

만일 같은 그림인데 평행이동한 경우에도 input이 달라 output도 다르게 나올 수 있다.

또한, 모든 pixel에 대하여 feature를 추출하므로 비효율 적이다.

이를 극복하기 위해서는 위치와 상관없이 Translate Invarient 하면서

필요한 정보만 조금씩 읽는 방법이 필요하다.

<br />
<br />

## Convolutional Layer

각 Input마다 Filter를 합성 연산하여 주변 공간에 대한 정보를 나타내는 방식이다.

Filter란 각 Input에 특정 방향에 대한 특징을 포착할 수 있도록 더해주는 역할을 한다.

Filter는 보통 3 x 3 , 5 x 5, 7 x 7 등 홀수 개수로 연산을 진행한다.

<br />

![90454590](https://user-images.githubusercontent.com/86182583/131298512-2301eb08-b21e-484d-937f-3b77157d87b1.jpg)

이렇게 특정 방향을 향한 필터들을 통하면 그 방향에 관한 선의 특징을 아래와 같이 더 쉽게 포착할 수 있게 된다.

![conv-line-detection-horizonta](https://user-images.githubusercontent.com/86182583/131298888-c3214e28-51d5-47a9-ae4d-229b42a8142d.jpg)

<br />

### 계산방법

![Convolution_schematic](https://user-images.githubusercontent.com/86182583/131303153-dd062dad-ca1a-4325-a664-239d13a36e45.gif)

각 Input 마다 계산은 다음과 같이 한다.

1. Input에서 최외각에는 Filter를 적용시킬 수 없다. 그 안쪽부터 필터를 덧대고 각 칸에 일치하는 위치끼리 곱한다.

2. 이 곱해서 나온 값을 다 더해서 Output의 한 칸으로 계산하게 한다.

이 규칙에 따르면 Output의 형태는 {(Input width) - (filter width) + 1} * {(Input height) - (filter height) + 1} 다.

예시) 7 x 7 input에 3 x 3 filter를 적용시키면 = (7-3+1) x (7-3+1) = 5 x 5 형태로 나온다.

![filter_capture](https://user-images.githubusercontent.com/86182583/131428896-68558609-cc67-40b7-99fe-040eff8f3efc.PNG)

한 칸 씩 이동하면서 계산을 한다.

3. 이미지에 가로/세로/대각선 필터 등 여러 개를 적용하고 sliding 하면서 연산을 실행한다.

따라서 모든 pixel 간 feature를 추출하는 비효율적인 방식이 아니라 **인접한 정보끼리만 연산하도록 하여 Local 관계**를 나타내준다.

또한 sliding을 통해 **Filter가 Feature를 표현해 주는 것이라면, 위치에 상관 없이 해당 Feature를 추출 가능하다.**

![mousefilter](https://user-images.githubusercontent.com/86182583/131442428-ab80a353-a4e6-4b5a-8c9f-320b195de49a.jpeg)

쥐가 이제 이미지 영역 어디로 이동하든 전부 다 sliding 하면서 훑기 때문에 문제가 해결된다.

<br />

단, 이런 식으로 이미지를 계산하면 지속적으로 학습시키려면 연산 시간이 오래 걸릴 것은 자명하다.

이를 해결하기 위해서 sliding 간격을 늘리는 방식으로 학습하면 된다. 이를 **Stride**라고 한다.

다만 연산 속도가 빨라지는 대신 정확성이 trade-off 되는 점을 감안해야 한다.

또한 output 또한 바뀐다. 2깐씩 뛰기 때문에 그만큼 Output 크기도 줄어든다. (빨리 줄어들면 덜 학습해도 된다)

엄밀하게 수식으로 표현하면 다음과 같다. (padding은 바로 뒤에서 설명 예정)

<br />

![ohow](https://user-images.githubusercontent.com/86182583/131455691-03e0114e-e912-4541-8b72-776c3e9b43d8.PNG)

![ohowex](https://user-images.githubusercontent.com/86182583/131455952-6d9dcef5-ef36-4d4e-a5f9-9fb18a5f8748.PNG)

<br />

추가로 image는 RGB 등 Layer가 여러개일 수 있다.

이때 Filter는 모든 Layer에 적용되어 sliding을 하는 것을 알아야한다.

이 결과값을 Activation Map이라 한다.

다만 filter 또한 하나가 아니라 여러개가 나오는데, 그만큼 Activation Map 들이 늘어난다.

따라서 No. of Filters = No. of Activation 이다.

![filter_activation](https://user-images.githubusercontent.com/86182583/131638584-9e41db80-7b67-4a93-856b-5bd6ca7451a8.PNG)

<br />

### Padding

Input의 최외각 부분을 둘러준다. 이를 통해 기존 Input의 크기를 Output과 맞춰줄 수 있다. (Depth 제외)

많은 경우에는 0으로 두르는데, 이를 Zero Padding 이라고도 한다.

![zero_padding](https://user-images.githubusercontent.com/86182583/131467044-c26045af-253c-4322-aa54-e88d72852bcc.png)

<br />

### Pooling

Downsampling : 중요한 부분만 요약하여 축소하는 방식이다.

설정한 pool_size 안에서 조건에 대표값만 output으로 표현한다.

이를 통해 Overfitting 방지 효과가 있다.

대표적인 것은 pool의 평균값을 Average Pooling, 최대값을 나타내는 Max Pooling 등이 있다.

![poooling](https://user-images.githubusercontent.com/86182583/131596417-3383671c-4183-49c8-a56c-a150892b3069.PNG)

일반적으로 Convolution 1번 하면 Max-pooling을 하지만, 필수로 해야하는 것은 아니다.

Average pooling은 눈에 띄는 feature를 추출하는데에 효과적이다.

### Dense Layer

Covolutional Layer 자체는 feature를 효율적으로 추출해준다.

하지만 convolutoinal layer 자체에 classification 기능이 없다.

따라서 output을 flatten한 다음 Dense Layer를 거쳐서 분류를 해준다.

따라서 CNN 모델은 다음과 같은 과정을 거쳐서 학습된다.

![CNN_ALL](https://user-images.githubusercontent.com/86182583/131603762-0d2f6817-7dd9-4b74-b105-61e77751e389.jpeg)


<br />
<br />
